# Backend

This folder holds server-side logic for the Law Advisor application: DB connection, ingestion, indexing and the retrieval-based chatbot logic.

Key modules
- `db.py` â€” MongoDB primary connector with TinyDB UTFâ€‘8 fallback. Provides `ensure_connection()`, `insert_passage()`, `text_search()`.
- `search.py` â€” retrieval stack (keyword search, TFâ€‘IDF and optional embedding search). Use `retrieve(query, k, mode)`.
- `indexer.py` â€” builds TFâ€‘IDF (`build_tfidf()`) and optional embeddings (`build_embeddings()`).
- `ingest.py`, `ingest_file.py`, `ingest_all.py` â€” scripts to ingest JSON law files into MongoDB or TinyDB and rebuild indices.
- `bot.py` â€” compose answers from retrieved passages, includes scenario analysis and confidence scoring.

How to rebuild the TFâ€‘IDF index
1. Ensure DB has up-to-date passages (run `python backend/ingest_file.py <path>` or `python backend/ingest_all.py`).
2. Run `python -c "from backend.indexer import build_tfidf; build_tfidf()"`.

Notes & gotchas
- Avoid importing `backend` at application import time if you rely on explicit ingestion. `backend/ingest.py` performs file I/O â€” ingestion runs only when invoked intentionally.
- TinyDB files are stored in `data/` and are read/written using UTFâ€‘8 storage wrappers to support Vietnamese.
# ğŸ¤– Backend Module

Core search, database, and retrieval components for the law query system.

## ğŸ“‚ Files

```
backend/
â”œâ”€â”€ bot.py                  # Chatbot engine (imports from chatbot/)
â”œâ”€â”€ search.py               # Search engine
â”œâ”€â”€ db.py                   # Database layer
â”œâ”€â”€ indexer.py              # TF-IDF indexing
â”œâ”€â”€ ingest.py               # Data ingestion
â””â”€â”€ __init__.py

Note: Chatbot-specific modules (learning, sentiment, conversation, NLG)
are now in the dedicated chatbot/ folder for better organization.
See chatbot/README.md for details.
```

## ğŸ¤– Bot Engine (`bot.py`)

Advanced retrieval-based chatbot with:
- Intent detection (article, definition, procedure, penalty, scenario)
- Scenario analysis for practical questions
- Multi-source synthesis
- Confidence scoring
- NLG integration for natural responses
- Sentiment-aware tone adjustment

### Key Functions

```python
answer_question(query, k=5, session_id=None, user_id="anonymous")
    Returns: {
        "answer": str,
        "confidence": float,
        "sentiment": str,
        "urgency": str,
        "interaction_id": str,
        "is_followup": bool
    }

detect_intent(query: str) -> str
    Returns: "greeting", "article", "definition", "procedure", 
             "penalty", "who", "general", "scenario"

detect_scenario_query(query: str) -> bool
    Returns: True if practical situation question
```

### Usage

```python
from backend.bot import answer_question

response = answer_question("Quyá»n sá»­ dá»¥ng Ä‘áº¥t lÃ  gÃ¬?", k=5)
print(response["answer"])
print(f"Confidence: {response['confidence']}")
print(f"Sentiment: {response['sentiment']}")
```

## ğŸ” Search Engine (`search.py`)

Multi-tier search pipeline:

1. **Embeddings** (if enabled) - Semantic search
2. **TF-IDF** - Ranking with keyword matching
3. **Keyword** - Fallback search
4. **Article** - Direct article lookup

### Usage

```python
from backend.search import retrieve

# Semantic + TF-IDF search
results = retrieve("chuyá»ƒn nhÆ°á»£ng quyá»n sá»­ dá»¥ng Ä‘áº¥t", k=5)

# Article-specific search
results = retrieve("Äiá»u 69", k=1, mode="article")

# Keyword search
results = retrieve("pháº¡t tiá»n", k=10, mode="keyword")
```

## ğŸ§  Learning Engine (`learning_engine.py`)

Bot learns from user feedback to improve responses.

### Key Features

- Records all Q&A interactions
- Saves user ratings (1-5 stars)
- Extracts patterns from positive feedback
- Finds similar questions (Jaccard similarity)
- Manages learned synonyms

### Usage

```python
from backend.learning_engine import get_learning_engine

engine = get_learning_engine()

# Record interaction
interaction_id = engine.record_interaction(
    query="Quyá»n sá»­ dá»¥ng Ä‘áº¥t?",
    answer="...",
    sources=[],
    user_id="user123"
)

# Submit feedback
engine.submit_feedback(interaction_id, rating=5, feedback="Great!")

# Find similar learned answers
similar = engine.find_similar_learned_answers("KhÃ¡i niá»‡m quyá»n?", top_k=3)

# Get stats
stats = engine.get_learning_stats()
print(f"Avg Rating: {stats['avg_rating']}")
```

### Data Files

- `data/learned_interactions.json` - All Q&A with ratings
- `data/learned_patterns.json` - Patterns from positive feedback
- `data/learned_synonyms.json` - Learned synonyms
- `data/feedback_stats.json` - Statistics

## ğŸ˜Š Sentiment Analyzer (`sentiment_analyzer.py`)

Understands user emotion and adjusts bot response tone.

### Sentiment Types

- **POSITIVE** - Happy, satisfied
- **NEGATIVE** - Unsatisfied, critical
- **NEUTRAL** - Normal, factual
- **FRUSTRATED** - Angry, annoyed
- **URGENT** - Time-critical

### Urgency Levels

- **LOW** - General questions
- **MEDIUM** - Some urgency
- **HIGH** - Time-sensitive
- **CRITICAL** - Emergency

### Usage

```python
from backend.sentiment_analyzer import get_sentiment_analyzer

analyzer = get_sentiment_analyzer()

# Detect sentiment
sentiment, confidence = analyzer.analyze_sentiment(
    "Sao tÃ´i láº¡i khÃ´ng Ä‘Æ°á»£c mua Ä‘áº¥t???"
)
print(f"{sentiment.value}: {confidence:.2f}")  # frustrated: 0.95

# Detect urgency
urgency, conf = analyzer.analyze_urgency(query)

# Get response tone
tone = analyzer.get_response_tone(sentiment, urgency)
print(tone["greeting"])  # "Xin lá»—i vÃ¬ sá»± khÃ³ chá»‹u!"

# Detect follow-up
is_followup = analyzer.is_follow_up_question("Váº­y thá»i háº¡n bao lÃ¢u?")

# Detect context
context = analyzer.detect_context_type(query)  # business, personal, legal, info
```

## ğŸ’¬ Conversation Manager (`conversation_manager.py`)

Manages conversation history and context.

### Features

- Create sessions
- Add messages
- Get context window
- Extract topics
- Track statistics

### Usage

```python
from backend.conversation_manager import get_conversation_manager

manager = get_conversation_manager()

# Create session
session_id = manager.create_session("user123", "Chat Session")

# Add messages
manager.add_message(session_id, "user", "Quyá»n sá»­ dá»¥ng Ä‘áº¥t lÃ  gÃ¬?")
manager.add_message(session_id, "bot", "...")

# Get context
context = manager.get_context_window(session_id, window_size=5)
print(context["topics"])  # ["Ä‘áº¥t", "quyá»n"]

# Get stats
stats = manager.get_conversation_stats(session_id)
print(f"Messages: {stats['total_messages']}")
```

### Data Files

- `data/conversations/{session_id}.json` - Conversation history

## ğŸ¨ NLG Engine (`nlg_engine.py`)

Natural Language Generation for diverse responses.

### Features

- Paraphrasing
- Synonym replacement
- Style adjustment (formal/informal/technical)
- Emoji addition
- Template-based generation

### Usage

```python
from backend.nlg_engine import get_nlg_engine

nlg = get_nlg_engine()

# Paraphrase
original = "NgÆ°á»i nÆ°á»›c ngoÃ i khÃ´ng Ä‘Æ°á»£c sá»Ÿ há»¯u Ä‘áº¥t nÃ´ng nghiá»‡p"
formal = nlg.paraphrase(original, style="formal")
informal = nlg.paraphrase(original, style="informal")

# Generate intro/transition
intro = nlg.generate_intro("intro")  # "Theo luáº­t Ä‘á»‹nh:"
trans = nlg.generate_transition("addition")  # "hÆ¡n ná»¯a"

# Add emoji
text_with_emoji = nlg.add_emojis("LÆ°u Ã½: quyá»n Ä‘Æ°á»£c xÃ¡c Ä‘á»‹nh")

# Compose rich answer
answer = nlg.compose_rich_answer({
    "intro": "DÆ°á»›i Ä‘Ã¢y lÃ  thÃ´ng tin:",
    "main": "Quyá»n sá»­ dá»¥ng Ä‘áº¥t...",
    "warning": "Cáº§n chÃº Ã½...",
    "conclusion": "VÃ¬ váº­y..."
})
```

## ğŸ—„ï¸ Database Layer (`db.py`)

Supports MongoDB and TinyDB.

```python
from backend.db import insert_passage, text_search, find_by_id

# Insert document
insert_passage({
    "tieu_de_luat": "Luáº­t Äáº¥t Äai 2024",
    "noi_dung": [...],
    "text": "..."
})

# Search
results = text_search("quyá»n sá»­ dá»¥ng", limit=10)

# Find by ID
doc = find_by_id("doc_123")
```

## ğŸ“‡ Data Ingestion (`ingest.py`)

Load law data from JSON files.

```bash
python backend/ingest.py
```

Reads from `scraper/data/` and loads into database.

## ğŸ”§ Indexing (`indexer.py`)

Build TF-IDF and semantic indexes.

```bash
python backend/indexer.py
```

Creates:
- `data/tfidf.joblib` - TF-IDF model
- `data/embeddings.joblib` - Embeddings (optional)

---

## ğŸ§ª Testing

```bash
python tests/test_new_features.py
```

Tests all backend modules with sample data.

---

## ğŸ“Š Performance

- Response time: < 1s (with caching)
- Memory: ~50MB for full system
- Learning effectiveness: 80%+ answer reuse

---

## ğŸ”— Integration

Backend modules integrate as:

```
User Query
    â†“
Sentiment Analyzer (tone)
    â†“
Learning Engine (check learned answers)
    â†“
Search Engine (retrieve passages)
    â†“
Bot Engine (compose answer)
    â†“
NLG Engine (paraphrase & format)
    â†“
Conversation Manager (save)
    â†“
Response to User
```

---

**Version 2.0 | Backend Module**
