"""
sentiment_analyzer.py - Ph√¢n t√≠ch c·∫£m x√∫c & context t·ª´ query c·ªßa ng∆∞·ªùi d√πng

T√≠nh nƒÉng:
- Detect t√¢m tr·∫°ng (t√≠ch c·ª±c, ti√™u c·ª±c, trung l·∫≠p)
- Nh·∫≠n di·ªán ƒë·ªô kh·∫©n c·∫•p (urgent, normal, general)
- Detect satisfaction level
- ƒêi·ªÅu ch·ªânh tone c·ªßa bot response
"""

import re
from typing import Dict, Tuple
from enum import Enum


class Sentiment(Enum):
    """C·∫£m x√∫c c·ªßa ng∆∞·ªùi d√πng"""
    POSITIVE = "positive"      # H√†i l√≤ng, t√≠ch c·ª±c
    NEGATIVE = "negative"      # Kh√¥ng h√†i l√≤ng, t·ª©c gi·∫≠n
    NEUTRAL = "neutral"        # B√¨nh th∆∞·ªùng, ƒë∆°n thu·∫ßn h·ªèi
    FRUSTRATED = "frustrated"  # B·ª±c b√£, kh√≥ ch·ªãu
    URGENT = "urgent"          # C·∫ßn g·∫•p, v·ªôi v√£


class Urgency(Enum):
    """M·ª©c ƒë·ªô kh·∫©n c·∫•p"""
    LOW = "low"              # Th√¥ng th∆∞·ªùng
    MEDIUM = "medium"        # C·∫ßn h·ªèi nh∆∞ng kh√¥ng c·∫•p b√°ch
    HIGH = "high"            # C·∫ßn g·∫•p
    CRITICAL = "critical"    # R·∫•t c·∫•p b√°ch


class SentimentAnalyzer:
    """Ph√¢n t√≠ch c·∫£m x√∫c v√† ng·ªØ c·∫£nh"""
    
    def __init__(self):
        # T·ª´ kh√≥a t√≠ch c·ª±c
        self.positive_keywords = {
            'c·∫£m ∆°n': 2, 'thanks': 2, 'thank you': 2,
            'tuy·ªát': 3, 'excellent': 3, 'great': 3,
            't·ªët': 1, 'good': 1,
            'hi·ªÉu': 1, 'clarify': 1,
            'r√µ': 1, 'clear': 1,
        }
        
        # T·ª´ kh√≥a ti√™u c·ª±c
        self.negative_keywords = {
            'kh√¥ng hi·ªÉu': 3, 'confused': 3, 'confusing': 3,
            'sai': 2, 'wrong': 2, 'incorrect': 2,
            'kh√¥ng ƒë√∫ng': 2, 'inaccurate': 2,
            'ph·ª©c t·∫°p': 1, 'complicated': 1, 'complex': 1,
            'kh√≥': 1, 'difficult': 1, 'hard': 1,
            't·ªá': 2, 'bad': 2, 'terrible': 2,
            'v√¥ d·ª•ng': 3, 'useless': 3,
        }
        
        # T·ª´ kh√≥a b·ª±c b√£/kh√≥ ch·ªãu
        self.frustration_keywords = {
            'sao': 1, 'why': 1,
            't·∫°i sao': 1, 'why not': 1,
            'kh√¥ng bi·∫øt': 1, "don't know": 1,
            'b·ªëi r·ªëi': 2, 'confused': 2, 'bewildered': 2,
            'm∆° h·ªì': 2, 'vague': 2, 'unclear': 2,
        }
        
        # T·ª´ kh√≥a kh·∫©n c·∫•p
        self.urgent_keywords = {
            'g·∫•p': 2, 'urgent': 2, 'ngay': 2,
            'ngay b√¢y gi·ªù': 3, 'immediately': 3, 'asap': 3,
            'c·∫•p b√°ch': 3, 'critical': 3, 'emergency': 3,
            's·∫Øp': 1, 's·∫Øp t·ªõi': 2, 'soon': 1,
            'deadline': 2,
            'h√¥m nay': 1, 'today': 1,
            'c·∫ßn g·∫•p': 3,
        }
        
        # T·ª´ kh√≥a y√™u c·∫ßu l√†m l·∫°i/c·∫£i thi·ªán
        self.retry_keywords = {
            'l·∫°i': 1, 'again': 1,
            'kh√°c': 1, 'other': 1,
            'h·ªèi l·∫°i': 1, 'ask again': 1,
            'hi·ªÉu sai': 2, 'misunderstood': 2,
            'kh√¥ng ph·∫£i': 1, "isn't": 1,
        }
    
    def analyze_sentiment(self, query: str) -> Tuple[Sentiment, float]:
        """
        Ph√¢n t√≠ch c·∫£m x√∫c c·ªßa query
        Returns: (Sentiment, confidence_score 0-1)
        """
        query_lower = query.lower()
        
        # Score t·ª´ng lo·∫°i c·∫£m x√∫c
        positive_score = self._calculate_keyword_score(query_lower, self.positive_keywords)
        negative_score = self._calculate_keyword_score(query_lower, self.negative_keywords)
        frustration_score = self._calculate_keyword_score(query_lower, self.frustration_keywords)
        urgent_score = self._calculate_keyword_score(query_lower, self.urgent_keywords)
        
        # Determine sentiment based on scores
        total_score = positive_score - negative_score
        
        if urgent_score > 2:
            return Sentiment.URGENT, min(1.0, urgent_score / 5)
        
        if frustration_score > 1.5:
            return Sentiment.FRUSTRATED, min(1.0, frustration_score / 5)
        
        if positive_score > negative_score:
            return Sentiment.POSITIVE, min(1.0, positive_score / 5)
        elif negative_score > 0:
            return Sentiment.NEGATIVE, min(1.0, negative_score / 5)
        else:
            return Sentiment.NEUTRAL, 0.5
    
    def analyze_urgency(self, query: str) -> Tuple[Urgency, float]:
        """
        Ph√¢n t√≠ch m·ª©c ƒë·ªô kh·∫©n c·∫•p
        Returns: (Urgency, confidence_score 0-1)
        """
        query_lower = query.lower()
        urgent_score = self._calculate_keyword_score(query_lower, self.urgent_keywords)
        
        # Ki·ªÉm tra pattern v·ªÅ deadline (ƒêi·ªÅu X tr∆∞·ªõc ng√†y Y)
        deadline_pattern = r"(tr∆∞·ªõc|by|deadline).*(ng√†y|date|th√°ng|month|nƒÉm|year)\s+(\d+)"
        has_deadline = bool(re.search(deadline_pattern, query_lower))
        
        if has_deadline or urgent_score >= 3:
            return Urgency.CRITICAL, min(1.0, urgent_score / 5)
        elif urgent_score >= 2:
            return Urgency.HIGH, min(1.0, urgent_score / 5)
        elif urgent_score >= 1:
            return Urgency.MEDIUM, min(1.0, urgent_score / 5)
        else:
            return Urgency.LOW, 0.3
    
    def is_follow_up_question(self, query: str) -> bool:
        """Detect if this is a follow-up question (h·ªèi l·∫°i, h·ªèi th√™m)"""
        retry_score = self._calculate_keyword_score(query.lower(), self.retry_keywords)
        
        # Ho·∫∑c check pattern nh∆∞ "V·∫≠y n·∫øu...", "N·∫øu v·∫≠y..."
        followup_patterns = [
            r"v·∫≠y (n·∫øu|khi|th√¨|m√†)",
            r"n·∫øu v·∫≠y",
            r"nghe ƒë√¢u",
            r"c√≤n",
            r"th√™m v·ªÅ",
            r"chi ti·∫øt h∆°n",
            r"more details",
            r"what if"
        ]
        
        has_followup_pattern = any(re.search(p, query.lower()) for p in followup_patterns)
        
        return retry_score > 0.5 or has_followup_pattern
    
    def get_response_tone(self, sentiment: Sentiment, urgency: Urgency) -> Dict[str, str]:
        """
        X√°c ƒë·ªãnh tone c·ªßa response d·ª±a tr√™n sentiment & urgency
        """
        tones = {
            # (Sentiment, Urgency) -> tone configuration
            (Sentiment.POSITIVE, Urgency.LOW): {
                "greeting": "C·∫£m ∆°n b·∫°n! üòä",
                "prefix": "Vui m·ª´ng l√† c√≥ th·ªÉ gi√∫p b·∫°n:",
                "suffix": "Hy v·ªçng c√¢u tr·∫£ l·ªùi n√†y h·ªØu √≠ch! üëç",
                "formality": "informal"
            },
            (Sentiment.POSITIVE, Urgency.HIGH): {
                "greeting": "Hi·ªÉu r·ªìi! T√¥i s·∫Ω gi√∫p ngay:",
                "prefix": "ƒê·ªÉ gi·∫£i quy·∫øt v·∫•n ƒë·ªÅ c·ªßa b·∫°n ngay:",
                "suffix": "Hy v·ªçng ƒëi·ªÅu n√†y gi√∫p b·∫°n k·ªãp th·ªùi! ‚úì",
                "formality": "semi-formal"
            },
            (Sentiment.NEUTRAL, Urgency.LOW): {
                "greeting": "T√¥i c√≥ th·ªÉ gi√∫p b·∫°n:",
                "prefix": "D∆∞·ªõi ƒë√¢y l√† th√¥ng tin:",
                "suffix": "H√£y cho t√¥i bi·∫øt n·∫øu c·∫ßn th√™m th√¥ng tin.",
                "formality": "formal"
            },
            (Sentiment.NEUTRAL, Urgency.HIGH): {
                "greeting": "Hi·ªÉu r·ªìi, b·∫°n c·∫ßn th√¥ng tin g·∫•p:",
                "prefix": "Th√¥ng tin c·∫ßn thi·∫øt:",
                "suffix": "Hy v·ªçng ƒëi·ªÅu n√†y gi·∫£i quy·∫øt ƒë∆∞·ª£c v·∫•n ƒë·ªÅ c·ªßa b·∫°n.",
                "formality": "semi-formal"
            },
            (Sentiment.FRUSTRATED, Urgency.LOW): {
                "greeting": "Xin l·ªói n·∫øu c√¢u h·ªèi tr∆∞·ªõc kh√¥ng r√µ. ƒê·ªÉ t√¥i gi·∫£i th√≠ch l·∫°i:",
                "prefix": "ƒê·ªÉ l√†m cho v·∫•n ƒë·ªÅ n√†y r√µ r√†ng h∆°n:",
                "suffix": "N·∫øu v·∫´n c√≤n v·∫•n ƒë·ªÅ ƒë·ªÅ, h√£y b√°o cho t√¥i bi·∫øt.",
                "formality": "semi-formal"
            },
            (Sentiment.FRUSTRATED, Urgency.HIGH): {
                "greeting": "T√¥i hi·ªÉu b·∫°n b·ª©c x√∫c. ƒê·ªÉ gi·∫£i quy·∫øt ngay:",
                "prefix": "Th√¥ng tin quan tr·ªçng nh·∫•t m√† b·∫°n c·∫ßn:",
                "suffix": "Xin l·ªói v√¨ s·ª± kh√≥ ch·ªãu n√†y. B·∫°n c√≥ c·∫ßn t√¥i gi·∫£i th√≠ch th√™m kh√¥ng?",
                "formality": "semi-formal"
            },
            (Sentiment.NEGATIVE, Urgency.LOW): {
                "greeting": "Xin l·ªói n·∫øu c√¢u tr·∫£ l·ªùi tr∆∞·ªõc kh√¥ng ch√≠nh x√°c.",
                "prefix": "ƒê·ªÉ s·ª≠a l·∫°i:",
                "suffix": "C·∫£m ∆°n b·∫°n v√¨ ph·∫£n h·ªìi. T√¥i s·∫Ω c·∫£i thi·ªán.",
                "formality": "formal"
            },
            (Sentiment.NEGATIVE, Urgency.HIGH): {
                "greeting": "Xin l·ªói! ƒê·ªÉ s·ª≠a ngay:",
                "prefix": "Th√¥ng tin ch√≠nh x√°c:",
                "suffix": "Xin l·ªói v√¨ s·ª± nh·∫ßm l·∫´n. B·∫°n c√≥ c·∫ßn th√™m h·ªó tr·ª£ kh√¥ng?",
                "formality": "semi-formal"
            },
            (Sentiment.URGENT, Urgency.CRITICAL): {
                "greeting": "‚ö†Ô∏è V·∫•n ƒë·ªÅ c·∫•p b√°ch! T√¥i s·∫Ω gi·∫£i quy·∫øt ngay:",
                "prefix": "Th√¥ng tin T√åM KI·∫æM:",
                "suffix": "ƒê√¢y l√† th√¥ng tin c·∫•p b√°ch. Li√™n h·ªá c∆° quan h·ªØu quan n·∫øu c·∫ßn th√™m h·ªó tr·ª£.",
                "formality": "urgent"
            }
        }
        
        # T√¨m tone ph√π h·ª£p
        tone = tones.get((sentiment, urgency))
        
        if not tone:
            # Fallback to neutral tone
            tone = tones[(Sentiment.NEUTRAL, Urgency.LOW)]
        
        return tone
    
    def suggest_question_improvements(self, query: str) -> list:
        """G·ª£i √Ω c√°ch h·ªèi t·ªët h∆°n"""
        suggestions = []
        
        if len(query) < 10:
            suggestions.append("üí° C√¢u h·ªèi c√≥ v·∫ª qu√° ng·∫Øn. H√£y th√™m chi ti·∫øt ƒë·ªÉ t√¥i hi·ªÉu t·ªët h∆°n.")
        
        if query.endswith("?") is False and query.endswith("„ÄÇ") is False:
            suggestions.append("üí° C√¢u h·ªèi n√™n k·∫øt th√∫c b·∫±ng d·∫•u '?' ƒë·ªÉ r√µ r√†ng h∆°n.")
        
        if "ƒêi·ªÅu" not in query and "ƒëi·ªÅu" not in query.lower():
            # Kh√¥ng nh·∫Øc ƒë·∫øn ƒêi·ªÅu lu·∫≠t c·ª• th·ªÉ
            if any(word in query.lower() for word in ["quy·ªÅn", "nghƒ©a v·ª•", "vi ph·∫°m"]):
                suggestions.append("üí° N·∫øu mu·ªën h·ªèi v·ªÅ ƒêi·ªÅu c·ª• th·ªÉ, h√£y n√™u s·ªë ƒêi·ªÅu (v√≠ d·ª•: 'ƒêi·ªÅu 69')")
        
        return suggestions
    
    def _calculate_keyword_score(self, text: str, keywords: dict) -> float:
        """Calculate score based on keywords found in text"""
        score = 0.0
        for keyword, weight in keywords.items():
            if keyword in text:
                score += weight
        return score
    
    def detect_context_type(self, query: str) -> str:
        """Detect lo·∫°i context c·ªßa query"""
        query_lower = query.lower()
        
        # Business context
        if any(w in query_lower for w in ['kinh doanh', 'doanh nghi·ªáp', 'l·ª£i nhu·∫≠n', 'thu nh·∫≠p', 'business']):
            return 'business'
        
        # Personal context
        if any(w in query_lower for w in ['c√° nh√¢n', 'gia ƒë√¨nh', 'personal', 'family', 't√¥i', 'm√¨nh']):
            return 'personal'
        
        # Legal consultation
        if any(w in query_lower for w in ['t∆∞ v·∫•n', 's∆∞', 'lawyer', 'h·ªèi', 'advice']):
            return 'legal_consultation'
        
        # General information seeking
        return 'information'


# Global instance
_analyzer = None

def get_sentiment_analyzer() -> SentimentAnalyzer:
    """Get ho·∫∑c t·∫°o global sentiment analyzer instance"""
    global _analyzer
    if _analyzer is None:
        _analyzer = SentimentAnalyzer()
    return _analyzer
